#!/usr/bin/env python

import os
import re
import sys
import hashlib
import string
import optparse
import sqlite3
import subprocess
import multiprocessing
import email.parser

from os.path import *
from stat import *

# Initialize globals

mail_home  = join(os.environ['HOME'], 'Library', 'Mail')
mail_db    = join(mail_home, 'Messages')
mail_dir   = join(mail_home, 'Maildir')
news_dir   = join(mail_home, 'Newsdir')
mirror_dir = join(mail_home, 'Mirror')

parser = optparse.OptionParser()
parser.add_option("-v", "--verbose",
                  action="store_true", dest="verbose", default=False,
                  help="report activity options.verbosely")

(options, args) = parser.parse_args()


# Implementation of the various commands

def update_mirror():
    print >>sys.stderr, "Updating Mail/News eml mirror"

def message_inserter(conn, cursor, q):
    count = 0
    while True:
        (msgid, path, ismail) = q.get(block=True, timeout=None)
        if not msgid:
            q.task_done()
            break

        path = path[len(mail_home) + 1:]
        cursor.execute('''
    INSERT OR REPLACE INTO msgids (message_id, path, is_mail)
        VALUES (?, ?, ?)''', (msgid, path, 1 if ismail else 0))

        count += 1
        if count % 1000 == 0:
            print >>sys.stderr, "Scanned %d messages..." % count
            conn.commit()
        q.task_done()

    print >>sys.stderr, "Done scanning messages..."
    conn.commit()

class message_queuer:
    def __init__(self, queue):
        self.queue = queue

    def __call__(self, path):
        msgid = None
        with open(path, 'r') as fd:
            for line in fd.readlines():
                match = re.match('message-id:\s*(<[^>]+>)', line, re.IGNORECASE)
                if match:
                    msgid = match.group(1)
                    break

        if msgid:
            self.queue.put((msgid, path,
                            True if re.search('Maildir', path) else False))
        else:
            print >>sys.stderr, "No msgid in:", path

def update_database():
    print >>sys.stderr, "Updating Message database"
    create_table = False
    if not isfile(mail_db):
        create_table = True

    msgs   = sqlite3.connect(mail_db)
    cursor = msgs.cursor()

    if create_table:
        cursor.execute('''CREATE TABLE
    msgids
    (
        message_id TEXT(255) NOT NULL,
        path TEXT(4096) NOT NULL,
        is_mail INTEGER NOT NULL,
        PRIMARY KEY (message_id),
        UNIQUE (message_id)
    )''')

    try:
        manager = multiprocessing.Manager()
        q       = manager.Queue()
        pool    = multiprocessing.Pool(32)
        p       = multiprocessing.Process(target=message_inserter,
                                          args=(msgs, cursor, q))
        p.start()
        queuer = message_queuer(q)
        for directory in (join(news_dir, 'comp'),
                          join(news_dir, 'gmane'),
                          join(news_dir, 'gnu'),
                          join(news_dir, 'soc'),
                          join(news_dir, 'wg21')):
            for root, dirs, files in os.walk(directory):
                pool.map(queuer, (join(root, n) for n in files
                                  if re.match('(^[0-9]+(\.|$)|\.emlx?$)', n)))
        q.put((None, None, None))
        q.join()
        p.join()
    finally:
        cursor.close()

def update_git():
    print >>sys.stderr, "Updating git repositories"

def expire_articles():
    print >>sys.stderr, "Expiring articles"

def link_duplicates():
    print >>sys.stderr, "Linking duplicates"

def message_remover(conn, cursor, q):
    count = 0
    paths = []
    while True:
        (msgid, path, ismail) = q.get(block=True, timeout=None)
        if not msgid:
            q.task_done()
            break

        count += 1
        if count % 1000 == 0:
            print >>sys.stderr, "Scanned %d messages..." % count
            conn.commit()

        cursor.execute('SELECT message_id FROM msgids WHERE message_id=?',
                       (msgid,))
        for row in cursor:
            paths.append(path)
            break

        q.task_done()

    print >>sys.stderr, "Removing %d duplicates..." % len(paths)
    map(os.remove, paths)
    print >>sys.stderr, "Done Removing duplicates..."

def remove_duplicates():
    print >>sys.stderr, "Removing duplicate messages in current directory"

    msgs   = sqlite3.connect(mail_db)
    cursor = msgs.cursor()

    try:
        manager = multiprocessing.Manager()
        q       = manager.Queue()
        pool    = multiprocessing.Pool(32)
        p       = multiprocessing.Process(target=message_remover,
                                          args=(msgs, cursor, q))
        p.start()
        queuer = message_queuer(q)
        for root, dirs, files in os.walk(os.getcwd()):
            pool.map(queuer, (join(root, n) for n in files
                              if re.search('(^[0-9]+(\.|$)|\.emlx?$)', n)))
        q.put((None, None, None))
        q.join()
        p.join()

    finally:
        cursor.close()

def pack_mail():
    os.system("packmail")

def pack_news():
    os.system("packnews")

def do_everything():
    global commands
    map(lambda x: commands[x](),
        (i for i in commands if i != 'all' and i != 'remove_dups'))

# Command-line driver

commands = {
    'mirror':      update_mirror,
    'updatedb':    update_database,
    'git':         update_git,
    'expire':      expire_articles,
    'linkdups':    link_duplicates,
    'remove_dups': remove_duplicates,
    'packmail':    pack_mail,
    'packnews':    pack_news,
    'all':         do_everything
}

map(lambda x: commands[x](), (i for i in commands if i in args))
